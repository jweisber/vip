<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="18 The Problem of Priors | Odds &amp; Ends" />
<meta property="og:type" content="book" />

<meta property="og:image" content="img/social_image.png" />
<meta property="og:description" content="An open access textbook for introductory philosophy courses on probability and inductive logic." />
<meta name="github-repo" content="jweisber/vip" />

<meta name="author" content="Jonathan Weisberg" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="An open access textbook for introductory philosophy courses on probability and inductive logic.">

<title>18 The Problem of Priors | Odds &amp; Ends</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@jweisber" />
<meta name="twitter:creator" content="@jweisber" />
<meta name="twitter:title" content="18 The Problem of Priors | Odds &amp; Ends" />
<meta name="twitter:description" content="An open access textbook for introductory philosophy courses on probability and inductive logic." />
<meta name="twitter:image" content="img/social_image.png" />


<!--
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["output/HTML-CSS"],
  "HTML-CSS": {
    availableFonts: ["Gyre-Pagella"],
    preferredFont: "Gyre-Pagella",
    webFont: "Gyre-Pagella",
    imageFont: "Gyre-Pagella"
  }
});
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
-->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      extensions: ["color.js"]
    }
  });
</script>




<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="custom.css" type="text/css" />

</head>

<body>


<div style="display: none;">
$$
  \newcommand{\given}{\mid}
  \renewcommand{\neg}{\mathbin{\sim}}
  \renewcommand{\wedge}{\mathbin{\&}}
  \newcommand{\p}{Pr}
  \newcommand{\deg}{^{\circ}}
  \newcommand{\E}{E}
  \newcommand{\EU}{EU}
  \newcommand{\u}{U}
  \newcommand{\pr}{Pr}
  \newcommand{\po}{Pr^*}
  \definecolor{bookred}{RGB}{228,6,19}
  \definecolor{bookblue}{RGB}{0,92,169}
  \definecolor{bookpurple}{RGB}{114,49,94} 
$$
</div>

<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li class="part"><span><b>Part I</b></span></li>
<li class="has-sub"><a href="the-monty-hall-problem.html#the-monty-hall-problem"><span class="toc-section-number">1</span> The Monty Hall Problem</a><ul>
<li><a href="the-monty-hall-problem.html#diagramming-the-solution"><span class="toc-section-number">1.1</span> Diagramming the Solution</a></li>
<li><a href="the-monty-hall-problem.html#lessons"><span class="toc-section-number">1.2</span> Lessons Learned</a></li>
<li><a href="the-monty-hall-problem.html#exercises">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="logic.html#logic"><span class="toc-section-number">2</span> Logic</a><ul>
<li><a href="logic.html#validity-soundness"><span class="toc-section-number">2.1</span> Validity &amp; Soundness</a></li>
<li><a href="logic.html#propositions"><span class="toc-section-number">2.2</span> Propositions</a></li>
<li><a href="logic.html#visualizing-propositions"><span class="toc-section-number">2.3</span> Visualizing Propositions</a></li>
<li><a href="logic.html#strength"><span class="toc-section-number">2.4</span> Strength</a></li>
<li><a href="logic.html#indargs"><span class="toc-section-number">2.5</span> Forms of Inductive Argument</a></li>
<li><a href="logic.html#exercises-1">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="truth-tables.html#truth-tables"><span class="toc-section-number">3</span> Truth Tables</a><ul>
<li><a href="truth-tables.html#connectives"><span class="toc-section-number">3.1</span> Connectives</a></li>
<li><a href="truth-tables.html#truth-tables-1"><span class="toc-section-number">3.2</span> Truth Tables</a></li>
<li><a href="truth-tables.html#logical-truths-contradictions"><span class="toc-section-number">3.3</span> Logical Truths &amp; Contradictions</a></li>
<li><a href="truth-tables.html#mutual-exclusivity-truth-tables"><span class="toc-section-number">3.4</span> Mutual Exclusivity &amp; Truth Tables</a></li>
<li><a href="truth-tables.html#entailment-equivalence"><span class="toc-section-number">3.5</span> Entailment &amp; Equivalence</a></li>
<li><a href="truth-tables.html#summary"><span class="toc-section-number">3.6</span> Summary</a></li>
<li><a href="truth-tables.html#exercises-2">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="the-gamblers-fallacy.html#the-gamblers-fallacy"><span class="toc-section-number">4</span> The Gambler’s Fallacy</a><ul>
<li><a href="the-gamblers-fallacy.html#independence"><span class="toc-section-number">4.1</span> Independence</a></li>
<li><a href="the-gamblers-fallacy.html#fairness"><span class="toc-section-number">4.2</span> Fairness</a></li>
<li><a href="the-gamblers-fallacy.html#the-gamblers-fallacy-1"><span class="toc-section-number">4.3</span> The Gambler’s Fallacy</a></li>
<li><a href="the-gamblers-fallacy.html#ignorance-is-not-a-fallacy"><span class="toc-section-number">4.4</span> Ignorance Is Not a Fallacy</a></li>
<li><a href="the-gamblers-fallacy.html#the-hot-hand-fallacy"><span class="toc-section-number">4.5</span> The Hot Hand Fallacy</a></li>
<li><a href="the-gamblers-fallacy.html#exercises-3">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="calculating-probabilities.html#calculating-probabilities"><span class="toc-section-number">5</span> Calculating Probabilities</a><ul>
<li><a href="calculating-probabilities.html#multiplying-probabilities"><span class="toc-section-number">5.1</span> Multiplying Probabilities</a></li>
<li><a href="calculating-probabilities.html#adding-probabilities"><span class="toc-section-number">5.2</span> Adding Probabilities</a></li>
<li><a href="calculating-probabilities.html#exclusivity-vs.independence"><span class="toc-section-number">5.3</span> Exclusivity vs. Independence</a></li>
<li><a href="calculating-probabilities.html#tautologies-contradictions-and-equivalent-propositions"><span class="toc-section-number">5.4</span> Tautologies, Contradictions, and Equivalent Propositions</a></li>
<li><a href="calculating-probabilities.html#the-language-of-events"><span class="toc-section-number">5.5</span> The Language of Events</a></li>
<li><a href="calculating-probabilities.html#summary-1"><span class="toc-section-number">5.6</span> Summary</a></li>
<li><a href="calculating-probabilities.html#exercises-4">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="conditional-probability.html#conditional-probability"><span class="toc-section-number">6</span> Conditional Probability</a><ul>
<li><a href="conditional-probability.html#calculating-conditional-probability"><span class="toc-section-number">6.1</span> Calculating Conditional Probability</a></li>
<li><a href="conditional-probability.html#conditional-probability-trees"><span class="toc-section-number">6.2</span> Conditional Probability &amp; Trees</a></li>
<li><a href="conditional-probability.html#more-examples"><span class="toc-section-number">6.3</span> More Examples</a></li>
<li><a href="conditional-probability.html#order-matters"><span class="toc-section-number">6.4</span> Order Matters</a></li>
<li><a href="conditional-probability.html#declaring-independence"><span class="toc-section-number">6.5</span> Declaring Independence</a></li>
<li><a href="conditional-probability.html#ch6ex">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="calculating-probabilities-part-ii.html#calculating-probabilities-part-ii"><span class="toc-section-number">7</span> Calculating Probabilities, Part II</a><ul>
<li><a href="calculating-probabilities-part-ii.html#the-negation-rule"><span class="toc-section-number">7.1</span> The Negation Rule</a></li>
<li><a href="calculating-probabilities-part-ii.html#the-general-addition-rule"><span class="toc-section-number">7.2</span> The General Addition Rule</a></li>
<li><a href="calculating-probabilities-part-ii.html#the-general-multiplication-rule"><span class="toc-section-number">7.3</span> The General Multiplication Rule</a></li>
<li><a href="calculating-probabilities-part-ii.html#laplaces-urn-puzzle"><span class="toc-section-number">7.4</span> Laplace’s Urn Puzzle</a></li>
<li><a href="calculating-probabilities-part-ii.html#the-law-of-total-probability"><span class="toc-section-number">7.5</span> The Law of Total Probability</a></li>
<li><a href="calculating-probabilities-part-ii.html#example"><span class="toc-section-number">7.6</span> Example</a></li>
<li><a href="calculating-probabilities-part-ii.html#exercises-5">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="chbayes.html#chbayes"><span class="toc-section-number">8</span> Bayes’ Theorem</a><ul>
<li><a href="chbayes.html#bayes-theorem"><span class="toc-section-number">8.1</span> Bayes’ Theorem</a></li>
<li><a href="chbayes.html#understanding-bayes-theorem"><span class="toc-section-number">8.2</span> Understanding Bayes’ Theorem</a></li>
<li><a href="chbayes.html#bayes-long-theorem"><span class="toc-section-number">8.3</span> Bayes’ Long Theorem</a></li>
<li><a href="chbayes.html#example-1"><span class="toc-section-number">8.4</span> Example</a></li>
<li><a href="chbayes.html#baserate"><span class="toc-section-number">8.5</span> The Base Rate Fallacy</a></li>
<li><a href="chbayes.html#exercises-6">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="multiple-conditions.html#multiple-conditions"><span class="toc-section-number">9</span> Multiple Conditions</a><ul>
<li><a href="multiple-conditions.html#multiple-draws"><span class="toc-section-number">9.1</span> Multiple Draws</a></li>
<li><a href="multiple-conditions.html#multiple-witnesses"><span class="toc-section-number">9.2</span> Multiple Witnesses</a></li>
<li><a href="multiple-conditions.html#without-replacement"><span class="toc-section-number">9.3</span> Without Replacement</a></li>
<li><a href="multiple-conditions.html#multiplying-conditional-probabilities"><span class="toc-section-number">9.4</span> Multiplying Conditional Probabilities</a></li>
<li><a href="multiple-conditions.html#summary-2"><span class="toc-section-number">9.5</span> Summary</a></li>
<li><a href="multiple-conditions.html#exercises-7">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="probability-induction.html#probability-induction"><span class="toc-section-number">10</span> Probability &amp; Induction</a><ul>
<li><a href="probability-induction.html#generalizing-from-observed-instances"><span class="toc-section-number">10.1</span> Generalizing from Observed Instances</a></li>
<li><a href="probability-induction.html#real-life-is-more-complicated"><span class="toc-section-number">10.2</span> Real Life Is More Complicated</a></li>
<li><a href="probability-induction.html#bayesibe"><span class="toc-section-number">10.3</span> Inference to the Best Explanation</a></li>
</ul></li>
<li class="part"><span><b>Part II</b></span></li>
<li class="has-sub"><a href="expected-value.html#expected-value"><span class="toc-section-number">11</span> Expected Value</a><ul>
<li><a href="expected-value.html#expected-monetary-values"><span class="toc-section-number">11.1</span> Expected Monetary Values</a></li>
<li><a href="expected-value.html#visualizing-expectations"><span class="toc-section-number">11.2</span> Visualizing Expectations</a></li>
<li><a href="expected-value.html#more-than-two-outcomes"><span class="toc-section-number">11.3</span> More Than Two Outcomes</a></li>
<li><a href="expected-value.html#fair-prices"><span class="toc-section-number">11.4</span> Fair Prices</a></li>
<li><a href="expected-value.html#other-goods"><span class="toc-section-number">11.5</span> Other Goods</a></li>
<li><a href="expected-value.html#decision-tables"><span class="toc-section-number">11.6</span> Decision Tables</a></li>
<li><a href="expected-value.html#exercises-8">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="utility.html#utility"><span class="toc-section-number">12</span> Utility</a><ul>
<li><a href="utility.html#subjectivity-objectivity"><span class="toc-section-number">12.1</span> Subjectivity &amp; Objectivity</a></li>
<li><a href="utility.html#the-general-recipe"><span class="toc-section-number">12.2</span> The General Recipe</a></li>
<li><a href="utility.html#choosing-scales"><span class="toc-section-number">12.3</span> Choosing Scales</a></li>
<li><a href="utility.html#a-limitation-the-expected-utility-assumption"><span class="toc-section-number">12.4</span> A Limitation: The Expected Utility Assumption</a></li>
<li><a href="utility.html#the-value-of-money"><span class="toc-section-number">12.5</span> The Value of Money</a></li>
<li><a href="utility.html#exercises-9">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="challenges-to-expected-utility.html#challenges-to-expected-utility"><span class="toc-section-number">13</span> Challenges to Expected Utility</a><ul>
<li><a href="challenges-to-expected-utility.html#the-allais-paradox"><span class="toc-section-number">13.1</span> The Allais Paradox</a></li>
<li><a href="challenges-to-expected-utility.html#the-sure-thing-principle"><span class="toc-section-number">13.2</span> The Sure-thing Principle</a></li>
<li><a href="challenges-to-expected-utility.html#prescriptive-vs.descriptive"><span class="toc-section-number">13.3</span> Prescriptive vs. Descriptive</a></li>
<li><a href="challenges-to-expected-utility.html#the-ellsberg-paradox"><span class="toc-section-number">13.4</span> The Ellsberg Paradox</a></li>
<li><a href="challenges-to-expected-utility.html#ellsberg-allais"><span class="toc-section-number">13.5</span> Ellsberg &amp; Allais</a></li>
<li><a href="challenges-to-expected-utility.html#exercises-10">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="infinity-beyond.html#infinity-beyond"><span class="toc-section-number">14</span> Infinity &amp; Beyond</a><ul>
<li><a href="infinity-beyond.html#the-st.petersburg-paradox"><span class="toc-section-number">14.1</span> The St. Petersburg Paradox</a></li>
<li><a href="infinity-beyond.html#bernoullis-solution"><span class="toc-section-number">14.2</span> Bernoulli’s Solution</a></li>
<li><a href="infinity-beyond.html#st.petersburgs-revenge"><span class="toc-section-number">14.3</span> St. Petersburg’s Revenge</a></li>
<li><a href="infinity-beyond.html#pascals-wager"><span class="toc-section-number">14.4</span> Pascal’s Wager</a></li>
<li><a href="infinity-beyond.html#responses-to-pascals-wager"><span class="toc-section-number">14.5</span> Responses to Pascal’s Wager</a></li>
<li><a href="infinity-beyond.html#exercises-11">Exercises</a></li>
</ul></li>
<li class="part"><span><b>Part III</b></span></li>
<li class="has-sub"><a href="two-schools.html#two-schools"><span class="toc-section-number">15</span> Two Schools</a><ul>
<li><a href="two-schools.html#probability-as-frequency"><span class="toc-section-number">15.1</span> Probability as Frequency</a></li>
<li><a href="two-schools.html#probability-as-belief"><span class="toc-section-number">15.2</span> Probability as Belief</a></li>
<li><a href="two-schools.html#which-kind-of-probability"><span class="toc-section-number">15.3</span> Which Kind of Probability?</a></li>
<li><a href="two-schools.html#frequentism"><span class="toc-section-number">15.4</span> Frequentism</a></li>
<li><a href="two-schools.html#bayesianism"><span class="toc-section-number">15.5</span> Bayesianism</a></li>
</ul></li>
<li class="has-sub"><a href="beliefs-betting-rates.html#beliefs-betting-rates"><span class="toc-section-number">16</span> Beliefs &amp; Betting Rates</a><ul>
<li><a href="beliefs-betting-rates.html#measuring-personal-probabilities"><span class="toc-section-number">16.1</span> Measuring Personal Probabilities</a></li>
<li><a href="beliefs-betting-rates.html#things-to-watch-out-for"><span class="toc-section-number">16.2</span> Things to Watch Out For</a></li>
<li><a href="beliefs-betting-rates.html#indirect-measurements"><span class="toc-section-number">16.3</span> Indirect Measurements</a></li>
<li><a href="beliefs-betting-rates.html#exercises-12">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="dutch-books.html#dutch-books"><span class="toc-section-number">17</span> Dutch Books</a><ul>
<li><a href="dutch-books.html#dutch-books-1"><span class="toc-section-number">17.1</span> Dutch Books</a></li>
<li><a href="dutch-books.html#bankteller"><span class="toc-section-number">17.2</span> The Bankteller Fallacy</a></li>
<li><a href="dutch-books.html#dutch-books-in-general"><span class="toc-section-number">17.3</span> Dutch Books in General</a></li>
<li><a href="dutch-books.html#exercises-13">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="priors.html#priors"><span class="toc-section-number">18</span> The Problem of Priors</a><ul>
<li><a href="priors.html#priors-posteriors"><span class="toc-section-number">18.1</span> Priors &amp; Posteriors</a></li>
<li><a href="priors.html#the-principle-of-indifference"><span class="toc-section-number">18.2</span> The Principle of Indifference</a></li>
<li><a href="priors.html#the-continuous-principle-of-indifference"><span class="toc-section-number">18.3</span> The Continuous Principle of Indifference</a></li>
<li><a href="priors.html#bertrands-paradox"><span class="toc-section-number">18.4</span> Bertrand’s Paradox</a></li>
<li><a href="priors.html#the-problem-of-priors"><span class="toc-section-number">18.5</span> The Problem of Priors</a></li>
<li><a href="priors.html#exercises-14">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="significance-testing.html#significance-testing"><span class="toc-section-number">19</span> Significance Testing</a><ul>
<li><a href="significance-testing.html#coincidence"><span class="toc-section-number">19.1</span> Coincidence</a></li>
<li><a href="significance-testing.html#making-it-precise"><span class="toc-section-number">19.2</span> Making it Precise</a></li>
<li><a href="significance-testing.html#levels-of-significance"><span class="toc-section-number">19.3</span> Levels of Significance</a></li>
<li><a href="significance-testing.html#normal-approximation"><span class="toc-section-number">19.4</span> Normal Approximation</a></li>
<li><a href="significance-testing.html#the-68-95-99-rule"><span class="toc-section-number">19.5</span> The 68-95-99 Rule</a></li>
<li><a href="significance-testing.html#binomial-probabilities"><span class="toc-section-number">19.6</span> Binomial Probabilities</a></li>
<li><a href="significance-testing.html#significance-testing-1"><span class="toc-section-number">19.7</span> Significance Testing</a></li>
<li><a href="significance-testing.html#warnings"><span class="toc-section-number">19.8</span> Warnings</a></li>
<li><a href="significance-testing.html#exercises-15">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="chlindley.html#chlindley"><span class="toc-section-number">20</span> Lindley’s Paradox</a><ul>
<li><a href="chlindley.html#significance-subjectivity"><span class="toc-section-number">20.1</span> Significance &amp; Subjectivity</a></li>
<li><a href="chlindley.html#making-it-concrete"><span class="toc-section-number">20.2</span> Making It Concrete</a></li>
<li><a href="chlindley.html#the-role-of-priors-in-significance-testing"><span class="toc-section-number">20.3</span> The Role of Priors in Significance Testing</a></li>
<li><a href="chlindley.html#lindleys-paradox"><span class="toc-section-number">20.4</span> Lindley’s Paradox</a></li>
<li><a href="chlindley.html#a-bayesian-analysis"><span class="toc-section-number">20.5</span> A Bayesian Analysis</a></li>
<li><a href="chlindley.html#exercises-16">Exercises</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="has-sub"><a href="cheat-sheet.html#cheat-sheet"><span class="toc-section-number">A</span> Cheat Sheet</a><ul>
<li><a href="cheat-sheet.html#deductive-logic">Deductive Logic</a></li>
<li><a href="cheat-sheet.html#probability">Probability</a></li>
<li><a href="cheat-sheet.html#decision-theory">Decision Theory</a></li>
<li><a href="cheat-sheet.html#bayesianism-1">Bayesianism</a></li>
<li><a href="cheat-sheet.html#frequentism-1">Frequentism</a></li>
</ul></li>
<li class="has-sub"><a href="the-axioms-of-probability.html#the-axioms-of-probability"><span class="toc-section-number">B</span> The Axioms of Probability</a><ul>
<li><a href="the-axioms-of-probability.html#theories-and-axioms">Theories and Axioms</a></li>
<li><a href="the-axioms-of-probability.html#the-three-axioms-of-probability">The Three Axioms of Probability</a></li>
<li><a href="the-axioms-of-probability.html#first-steps">First Steps</a></li>
<li><a href="the-axioms-of-probability.html#conditional-probability-the-multiplication-rule">Conditional Probability &amp; the Multiplication Rule</a></li>
<li><a href="the-axioms-of-probability.html#equivalence-general-addition">Equivalence &amp; General Addition</a></li>
<li><a href="the-axioms-of-probability.html#total-probability-bayes-theorem">Total Probability &amp; Bayes’ Theorem</a></li>
<li><a href="the-axioms-of-probability.html#independence-1">Independence</a></li>
</ul></li>
<li class="has-sub"><a href="grue.html#grue"><span class="toc-section-number">C</span> The Grue Paradox</a><ul>
<li><a href="grue.html#a-gruesome-concept">A Gruesome Concept</a></li>
<li><a href="grue.html#the-paradox">The Paradox</a></li>
<li><a href="grue.html#grue-artificial-intelligence">Grue &amp; Artificial Intelligence</a></li>
<li><a href="grue.html#disjunctivitis">Disjunctivitis</a></li>
<li><a href="grue.html#time-dependence">Time Dependence</a></li>
<li><a href="grue.html#the-moral">The Moral</a></li>
</ul></li>
<li class="has-sub"><a href="the-problem-of-induction.html#the-problem-of-induction"><span class="toc-section-number">D</span> The Problem of Induction</a><ul>
<li><a href="the-problem-of-induction.html#the-dilemma">The Dilemma</a></li>
<li><a href="the-problem-of-induction.html#the-problem-of-induction-vs.the-grue-paradox">The Problem of Induction vs. the Grue Paradox</a></li>
<li><a href="the-problem-of-induction.html#probability-theory-to-the-rescue">Probability Theory to the Rescue?</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="priors" class="section level1">
<h1><span class="header-section-number">18</span> The Problem of Priors</h1>
<div class="epigraph">
<p>
When my information changes, I alter my conclusions. What do you do, sir?<br />
—attributed to John Maynard Keynes
</p>
</div>
<p><span class="newthought">The</span> last two chapters showed how Bayesians make personal probabilities objective. They can be quantified using betting rates. And they are bound to the laws of probability by Dutch books.</p>
<p>But what about learning from evidence? Observation and evidence-based reasoning are the keystones of science. They’re supposed to separate the scientific method from other ways of viewing the world, like superstition or faith. So where do they fit into the Bayesian picture?</p>
<div id="priors-posteriors" class="section level2">
<h2><span class="header-section-number">18.1</span> Priors &amp; Posteriors</h2>
<p><span class="newthought">When</span> we observe something new, we change our beliefs. A doctor sees the results of her patient’s lab test and concludes he doesn’t have strep throat after all, just a bad cold.</p>
<p>In Bayesian terms, the beliefs you have before a change are called your <strong><em>priors</em></strong>. We denote your prior beliefs with the familiar operator <span class="math inline">\(\pr\)</span>. Your prior belief about hypothesis <span class="math inline">\(H\)</span> is written <span class="math inline">\(\p(H)\)</span>. The new beliefs you form based on the evidence are called your <strong><em>posteriors</em></strong>. We write <span class="math inline">\(\po\)</span> to distinguish them from what you believed before. So <span class="math inline">\(\po(H)\)</span> is your posterior belief in <span class="math inline">\(H\)</span>.</p>
<p>What’s the rule for changing your beliefs? When you get new evidence, how do you go from <span class="math inline">\(\pr(H)\)</span> to <span class="math inline">\(\po(H)\)</span>? Let’s start by thinking about an example.</p>
<p>Imagine you’re about to test a chemical with litmus paper to determine whether it’s an acid or a base. Before you do the test, you think it’s probably an acid if the paper turns red, and it’s probably a base if the paper turns blue. Suppose the paper turns red. Conclusion: the sample is probably an acid.</p>
<p>So your new belief in hypothesis <span class="math inline">\(H\)</span> is determined by your prior <em>conditional</em> belief. Before, you thought <span class="math inline">\(H\)</span> was probably true <em>if</em> <span class="math inline">\(E\)</span> is true. When you learn that <span class="math inline">\(E\)</span> in fact is true, you conclude that <span class="math inline">\(H\)</span> is probably true.</p>
<dl>
<dt>Conditionalization</dt>
<dd><p>When you learn new evidence <span class="math inline">\(E\)</span>, your posterior probability in hypothesis <span class="math inline">\(H\)</span> should match your prior conditional probability:
<span class="math display">\[ \po(H) = \pr(H \given E). \]</span></p>
</dd>
</dl>
<p>For example, imagine I’m going to roll a six-sided die behind a screen so you can’t see the result. But I’ll tell you whether the result is odd or even. Before I do, what is your personal probability that the die will land on a high number (either <span class="math inline">\(4\)</span>, <span class="math inline">\(5\)</span>, or <span class="math inline">\(6\)</span>)? Let’s assume your answer is <span class="math inline">\(\pr(H) = 1/2\)</span>.</p>
<p>Also before I tell you the result, what is your personal probability that the die will land on a high number <em>given that it lands on an even number</em>? Let’s assume your answer here is <span class="math inline">\(\pr(H \given E) = 2/3\)</span>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-134"></span>
<img src="_main_files/figure-html/unnamed-chunk-134-1.png" alt="Prior vs. posterior probabilities in a die-roll problem. $H$ $=$ the die landed $4$, $5$, or $6$. $E$ $=$ the die landed even. $Pr(H) = 1/2$, $Pr^*(H) = 2/3$." width="672"  />
<!--
<p class="caption marginnote">-->Figure 18.1: Prior vs. posterior probabilities in a die-roll problem. <span class="math inline">\(H\)</span> <span class="math inline">\(=\)</span> the die landed <span class="math inline">\(4\)</span>, <span class="math inline">\(5\)</span>, or <span class="math inline">\(6\)</span>. <span class="math inline">\(E\)</span> <span class="math inline">\(=\)</span> the die landed even. <span class="math inline">\(Pr(H) = 1/2\)</span>, <span class="math inline">\(Pr^*(H) = 2/3\)</span>.<!--</p>-->
<!--</div>--></span>
</p>
<p>Now I roll the die and I tell you it did in fact land even. What is your new personal probability that it landed on a high number? Following the Conditionalization rule, <span class="math inline">\(\po(H) = \pr(H \given E) = 2/3\)</span>.</p>
<p><span class="newthought">We</span> learned how to use <a href="chbayes.html#bayes-theorem">Bayes’ theorem</a> to calculate <span class="math inline">\(\pr(H \given E)\)</span>. If we combine Bayes’ theorem with Conditionalization we get:
<span class="math display">\[ \po(H) = \pr(H) \frac{\pr(E \given H)}{\pr(E)}. \]</span>
Because this formula is so useful for figuring out what conclusion to draw from new evidence, the Bayesian school of thought is named after it. Bayesian statisticians use it to evaluate evidence in actual scientific research. And Bayesian philosophers use it to explain the logic behind the scientific method.<label for="tufte-sn-8" class="margin-toggle sidenote-number">8</label><input type="checkbox" id="tufte-sn-8" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">8</span> We learned part of this story back in <a href="probability-induction.html#probability-induction">Chapter 10</a>.</span></p>
</div>
<div id="the-principle-of-indifference" class="section level2">
<h2><span class="header-section-number">18.2</span> The Principle of Indifference</h2>
<p><span class="newthought">Bayes’ theorem</span> provides an objective guide for <em>changing</em> your personal probabilities. Given the prior probabilities on the right hand side, you can calculate what your new probabilities should be on the left. But where do the prior probabilities on the right come from? Are there any objective rules for determining them? How do we calculate <span class="math inline">\(\pr(H)\)</span>, for example?</p>
<p>Let’s go back to our example where I roll a die behind a screen. Before I tell you whether the die landed on an even number, it seems reasonable to assign probability <span class="math inline">\(1/2\)</span> to the proposition that the die will land on a high number (<span class="math inline">\(4\)</span>, <span class="math inline">\(5\)</span>, or <span class="math inline">\(6\)</span>). But what if someone had a different prior probability, like <span class="math inline">\(\pr(H) = 1/10\)</span>?</p>
<p>That seems like a strange opinion to have. Why would they think the die is so unlikely to land on a high number, when there are just as many high numbers as low ones? On the other hand, if you don’t know whether the die is fair, it is possible it’s biased against high numbers. So maybe they’re on to something. And notice, assigning <span class="math inline">\(\pr(H) = 1/10\)</span> doesn’t violate the laws of probability, as long as they also assign <span class="math inline">\(\pr(\neg H) = 9/10\)</span>. So we couldn’t make a Dutch book against them.</p>
<p>Where do prior probabilities come from then? How do we decide whether to start with <span class="math inline">\(\pr(H) = 1/2\)</span> or <span class="math inline">\(\pr(H) = 1/10\)</span>? Here is a very natural proposal:</p>
<p><label for="tufte-mn-27" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-27" class="margin-toggle"><span class="marginnote"><span style="display: block;">The Principle of Indifference dates back to the very early days of probability theory. In fact <a href="logic.html#fig:laplace">Laplace</a> seems to have thought it was <em>the</em> central principle of probability.</span>
<span style="display: block;">For a long time it was known by a different name: “The Principle of Insufficient Reason”. The idea was that, without any reason to think one outcome more likely than another, they should all get the same probability.</span>
<span style="display: block;">In <span class="math inline"><span class="math inline">\(1921\)</span></span> it was renamed “The Principle of Indifference” by economist John Maynard Keynes (1883–1946). The idea behind the new name is that you should be indifferent about which outcome to bet on, since they all have the same probability of winning.</span></span></p>
<dl>
<dt>The Principle of Indifference</dt>
<dd><p>If there are <span class="math inline">\(n\)</span> possible outcomes, each outcome should have the same prior probability: <span class="math inline">\(1/n\)</span>.</p>
</dd>
</dl>
<p>In the die example, there are six possible outcomes. So each would have prior probability <span class="math inline">\(1/6\)</span>, and thus <span class="math inline">\(\pr(H) = 1/2\)</span>:
<span class="math display">\[
  \begin{aligned}
    \pr(H) &amp;= \pr(4) + \pr(5) + \pr(6)\\
          &amp;= 1/6 + 1/6 + 1/6\\
          &amp;= 1/2.
  \end{aligned}
\]</span></p>
<p>Here’s one more example. In North American roulette, the wheel has <span class="math inline">\(38\)</span> pockets, <span class="math inline">\(2\)</span> of which are green: zero (<span class="math inline">\(\mathtt{0}\)</span>) and double-zero (<span class="math inline">\(\mathtt{00}\)</span>). If you don’t know whether the wheel is fair, what should your prior probability be that the ball will land in a green pocket?</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-136"></span>
<img src="_main_files/figure-html/unnamed-chunk-136-1.png" alt="A North American roulette wheel" width="480"  />
<!--
<p class="caption marginnote">-->Figure 18.2: A North American roulette wheel<!--</p>-->
<!--</div>--></span>
</p>
<p>According to the Principle of Indifference, each space has equal probability, <span class="math inline">\(1/38\)</span>. So <span class="math inline">\(\pr(G) = 1/19\)</span>:
<span class="math display">\[
  \begin{aligned}
    \pr(G) &amp;= \pr(\mathtt{0}) + \pr(\mathtt{00})\\
           &amp;= 1/38 + 1/38\\
           &amp;= 1/19.
  \end{aligned}
\]</span></p>
</div>
<div id="the-continuous-principle-of-indifference" class="section level2">
<h2><span class="header-section-number">18.3</span> The Continuous Principle of Indifference</h2>
<p><span class="newthought">So</span> far so good, but there’s a problem. Sometimes the number of possible outcomes isn’t a finite number <span class="math inline">\(n\)</span>, it’s a continuum. Suppose you had to bet on the <em>angle</em> the roulette wheel will stop at, rather than just the colour it will land on. There’s a continuum of possible angles, from <span class="math inline">\(0\deg\)</span> to <span class="math inline">\(360\deg\)</span>. It could land at an angle of <span class="math inline">\(3\deg\)</span>, or <span class="math inline">\(314.1\deg\)</span>, or <span class="math inline">\(100\pi\deg\)</span>, etc.</p>
<p>So what’s the probability the wheel will stop at, say, an angle between <span class="math inline">\(180\deg\)</span> and <span class="math inline">\(270\deg\)</span>? Well, this range is <span class="math inline">\(1/4\)</span> of the whole range of possibilities from <span class="math inline">\(0\deg\)</span> to <span class="math inline">\(360\deg\)</span>. So the natural answer is <span class="math inline">\(1/4\)</span>. Generalizing this idea gives us another version of the Principle of Indifference.</p>
<dl>
<dt>Principle of Indifference (Continuous Version)</dt>
<dd><p>If there is an interval of possible outcomes from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>, the probability of any subinterval from <span class="math inline">\(c\)</span> to <span class="math inline">\(d\)</span> is: <span class="math display">\[\frac{d-c}{b-a}.\]</span></p>
</dd>
</dl>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-137"></span>
<img src="_main_files/figure-html/unnamed-chunk-137-1.png" alt="The continuous version of the Principle of Indifference: $Pr(H)$ is the length of the $c$-to-$d$ interval divided by the length of the whole $a$-to-$b$ interval." width="672"  />
<!--
<p class="caption marginnote">-->Figure 18.3: The continuous version of the Principle of Indifference: <span class="math inline">\(Pr(H)\)</span> is the length of the <span class="math inline">\(c\)</span>-to-<span class="math inline">\(d\)</span> interval divided by the length of the whole <span class="math inline">\(a\)</span>-to-<span class="math inline">\(b\)</span> interval.<!--</p>-->
<!--</div>--></span>
</p>
<p>The idea is that the prior probability of a hypothesis <span class="math inline">\(H\)</span> is just the proportion of possibilities where <span class="math inline">\(H\)</span> occurs. If the full range of possibilities goes from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>, and the subrange of <span class="math inline">\(H\)</span> possibilities is from <span class="math inline">\(c\)</span> to <span class="math inline">\(d\)</span>, then we just calculate how big that subrange is compared to the whole range.</p>
</div>
<div id="bertrands-paradox" class="section level2">
<h2><span class="header-section-number">18.4</span> Bertrand’s Paradox</h2>
<p><span class="newthought">Unfortunately</span>, there’s a serious problem with this way of thinking. In fact it’s so serious that the Principle of Indifference is not accepted as part of the modern theory of probability. You won’t find it in a standard mathematics or statistics textbook on probability.</p>
<p>What’s the problem? Imagine a factory makes square pieces of paper, whose sides always have length somewhere between <span class="math inline">\(1\)</span> and <span class="math inline">\(3\)</span> feet. What is the probability the sides of the next piece of paper they manufacture will be between <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> feet long?</p>
<p>Applying the Principle of Indifference we get <span class="math inline">\(1/2\)</span>:
<span class="math display">\[ \frac{d-c}{b-a} = \frac{2-1}{3-1} = \frac{1}{2}. \]</span>
That seems reasonable, but now suppose we rephrase the question. What is the probability that the <em>area</em> of the next piece of paper will be between <span class="math inline">\(1\)</span> ft<span class="math inline">\(^2\)</span> and <span class="math inline">\(4\)</span> ft<span class="math inline">\(^2\)</span>? Applying the Principle of Indifference again, we get a different number, <span class="math inline">\(3/8\)</span>:
<span class="math display">\[ \frac{d-c}{b-a} = \frac{4-1}{9-1} = \frac{3}{8}. \]</span>
But the answer should have been the same as before: it’s the same questions, just rephrased! If the sides are between <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> feet long, that’s the same as the area being between <span class="math inline">\(1\)</span> ft<span class="math inline">\(^2\)</span> and <span class="math inline">\(4\)</span> ft<span class="math inline">\(^2\)</span>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-138"></span>
<img src="img/bertrand.png" alt="Joseph Bertrand (1822--1900) presented this paradox in his $1889$ book *Calcul des Probabilités*. He used a different example though. Our example is a bit easier to understand, and comes from the book *Laws and Symmetry* by Bas van Fraassen." width="200"  />
<!--
<p class="caption marginnote">-->Figure 18.4: Joseph Bertrand (1822–1900) presented this paradox in his <span class="math inline">\(1889\)</span> book <em>Calcul des Probabilités</em>. He used a different example though. Our example is a bit easier to understand, and comes from the book <em>Laws and Symmetry</em> by Bas van Fraassen.<!--</p>-->
<!--</div>--></span>
</p>
<p>So which answer is right, <span class="math inline">\(1/2\)</span> or <span class="math inline">\(3/8\)</span>? It depends on which dimension we apply the Principle of Indifference to: length vs. area. And there doesn’t seem to be any principled way of deciding which dimension to use. So we don’t have a principled way to apply the Principle of Indifference.</p>
<p><label for="tufte-mn-28" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-28" class="margin-toggle"><span class="marginnote"><span style="display: block;">Here’s <a href="http://www.wi-phi.com/video/bertrands-paradox">a video explaining Bertrand’s paradox</a> thanks to wi-phi.com: <a href="http://www.wi-phi.com/video/bertrands-paradox"><img src="img/bertrand_screengrab.png" /></a></span></span></p>
<p><span class="newthought">There’s nothing special</span> about the example of the paper factory, the same problem comes up all the time. Take the continuous roulette wheel. Suppose the angle is stops at depends on how hard it’s spun. The wheel’s starting speed can be anywhere between <span class="math inline">\(1\)</span> and <span class="math inline">\(10\)</span> miles per hour, let’s suppose. And if it’s between <span class="math inline">\(2\)</span> and <span class="math inline">\(5\)</span> miles per hour, it lands at an angle between <span class="math inline">\(180\deg\)</span> and <span class="math inline">\(270\deg\)</span> degrees. Otherwise it lands at an angle outside that range.</p>
<p>If we apply the Principle of Indifference to the wheel’s starting speed we get a probability of <span class="math inline">\(1/3\)</span> that it will land at an angle between <span class="math inline">\(180\deg\)</span> and <span class="math inline">\(270\deg\)</span>:
<span class="math display">\[ \frac{d-c}{b-a} = \frac{5-2}{10-1} = \frac{1}{3}. \]</span>
But we got an answer of <span class="math inline">\(1/4\)</span> when we solved the same problem before. Once again, what answer we get depends on how we apply the Principle of Indifference. If we apply it to the final angle we get <span class="math inline">\(1/4\)</span>, if we apply it to the starting speed we get <span class="math inline">\(1/3\)</span>. And there doesn’t seem to be any principled way of deciding which way to go.</p>
</div>
<div id="the-problem-of-priors" class="section level2">
<h2><span class="header-section-number">18.5</span> The Problem of Priors</h2>
<p><span class="newthought">There</span> is no accepted solution to Bertrand’s paradox.</p>
<p>Some Bayesians think it shows that prior probabilities should be somewhat subjective. Your beliefs have to follow the laws of probability to avoid Dutch books. But beyond that you can start with whatever prior probabilities seem right to you. (The Principle of Indifference should be abandoned.)</p>
<p>Others think the paradox shows that Bayesianism is too subjective. The whole idea of “prior” and “posterior” probabilities was a mistake, say the frequentists. Probability isn’t a matter of personal beliefs. There are objective rules for using probability to evaluate a hypothesis, but Bayes’ theorem is the wrong way to go about it.</p>
<p>So what’s the right way, according to frequentism? The next two chapters introduce the frequentist method.</p>
</div>
<div id="exercises-14" class="section level2 unnumbered">
<h2>Exercises</h2>
<ol>
<li><p>Suppose a carpenter makes circular tables that always have a diameter between <span class="math inline">\(40\)</span> and <span class="math inline">\(50\)</span> inches. Use the Principle of Indifference to answer the following questions. (Give exact answers, not decimal approximations.)</p>
<ol style="list-style-type: lower-alpha">
<li>What is the probability the next table the carpenter makes will have a diameter of at least <span class="math inline">\(43\)</span> inches?</li>
<li>What is the probability the next table the carpenter makes will have either a diameter between <span class="math inline">\(41\)</span> and <span class="math inline">\(42\)</span> inches, or between <span class="math inline">\(47\)</span> and <span class="math inline">\(49\)</span> inches?</li>
<li>Recalculate the probabilities from parts (a) and (b), but this time apply the Principle of Indifference to circumference instead of diameter. Does this change what answers you get?</li>
<li>Recalculate the probabilities from parts (a) and (b), but this time apply the Principle of Indifference to area instead of diameter. Does this change what answers you get?</li>
</ol></li>
<li><p>Joe spends his afternoons whittling cubes that have a side length between <span class="math inline">\(2\)</span> and <span class="math inline">\(10\)</span> centimetres. Use the Principle of Indifference to answer the following questions. (Give exact answers, not decimal approximations.)</p>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that Joe’s next cube will have sides at least <span class="math inline">\(6\)</span> centimetres long?</li>
<li>What is the probability Joe’s next cube will either have sides shorter than <span class="math inline">\(4\)</span> centimetres or longer than <span class="math inline">\(7\)</span> centimetres?</li>
<li>Recalculate the probabilities from parts (a) and (b), but this time apply the Principle of Indifference to the area of each face, rather than the length of each side. Does this change what answers you get?</li>
<li>Recalculate the probabilities from parts (a) and (b), but this time apply the Principle of Indifference to volume. Is the result the same or different compared to the answers from parts (a), (b), and (c)?</li>
</ol></li>
<li><p>Joel is in New York and he needs to be in Montauk by <span class="math inline">\(4\)</span>:<span class="math inline">\(00\)</span> to meet Clementine. He boards a train departing at <span class="math inline">\(3\)</span>:<span class="math inline">\(00\)</span> and asks the conductor whether they’ll be in Montauk by <span class="math inline">\(4\)</span>:<span class="math inline">\(00\)</span>. The conductor says the train will arrive some time between <span class="math inline">\(3\)</span>:<span class="math inline">\(50\)</span> and <span class="math inline">\(4\)</span>:<span class="math inline">\(12\)</span>, but she refuses to be more specific.</p>
<ol style="list-style-type: lower-alpha">
<li>According to the Principle of Indifference, what is the probability that Joel will be in Montauk in time to meet Clementine?</li>
</ol>
<p>After thinking it over, Joel realizes that his odds may actually be better than that. It’s a <span class="math inline">\(60\)</span> mile trip to Montauk, so the train must travel at an average speed between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> miles per hour.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>What are <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>?</li>
<li>How fast must the train travel to get to Montauk by <span class="math inline">\(4\)</span>:<span class="math inline">\(00\)</span>?</li>
<li>According to the Principle of Indifference, what is the probability that the train will travel fast enough to get to Montauk by <span class="math inline">\(4\)</span>:<span class="math inline">\(00\)</span>?</li>
</ol></li>
<li><p>A factory makes triangular traffic signs. The height of their signs is always the same as the width of the base. And the base is always between <span class="math inline">\(3\)</span> and <span class="math inline">\(6\)</span> feet.</p>
<ol style="list-style-type: lower-alpha">
<li>According to the Principle of Indifference, what is the probability that the next sign produced will be between <span class="math inline">\(5\)</span> and <span class="math inline">\(6\)</span> feet high?</li>
<li>Explain how to reformulate the problem in part (a) so that the probability given by the Principle of Indifference changes.</li>
<li>Explain the challenge that cases like this pose for the theory of personal probability. What do critics of Bayesianism say these examples demonstrate about prior probabilities?</li>
</ol></li>
<li><p>A factory makes circular dartboards whose diameter is always between <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> feet.</p>
<ol style="list-style-type: lower-alpha">
<li>According to the Principle of Indifference, what is the probability that the next dartboard produced will have a diameter between <span class="math inline">\(1\)</span> and <span class="math inline">\(5/3\)</span> feet?</li>
<li>If we reformulate part (a) in terms of the dartboard’s area, what is the probability given by the Principle of Indifference then? (Reminder: the area of a circle with diameter <span class="math inline">\(d\)</span> is <span class="math inline">\(A = \pi/4 \times d^2\)</span>.)</li>
<li>Explain the challenge that cases like this pose for the theory of personal probability. What do critics of Bayesianism say these examples demonstrate about prior probabilities?</li>
</ol></li>
<li><p>Some bars water down their whisky to save money. Suppose the proportion of whisky to water at your local bar is always somewhere between <span class="math inline">\(1/2\)</span> and <span class="math inline">\(2\)</span>. That is, there’s always at least <span class="math inline">\(1\)</span> unit of whisky for every <span class="math inline">\(2\)</span> units of water. But there’s never more than <span class="math inline">\(2\)</span> units of whisky for every <span class="math inline">\(1\)</span> unit of water. Suppose you order a “whisky”.</p>
<ol style="list-style-type: lower-alpha">
<li>According to the Principle of Indifference, what is the probability that it will be mostly whisky? (“Mostly” means more than half.)</li>
<li>What is the maximum possible proportion water to whisky?</li>
<li>What is the minimum possible proportion water to whisky?</li>
<li>Now calculate the probability that your drink will be less than <span class="math inline">\(1/2\)</span> water again, but this time apply the Principle of Indifference to the proportion of water to whisky. Is the result the same or different?</li>
</ol></li>
</ol>

</div>
</div>
<p style="text-align: center;">
<a href="dutch-books.html"><button class="btn btn-default">Previous</button></a>
<a href="significance-testing.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
